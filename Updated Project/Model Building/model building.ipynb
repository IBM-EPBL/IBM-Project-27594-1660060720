{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accf0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Model\n",
    "#create model\n",
    "model =Sequential()\n",
    "#adding model Layer\n",
    "model.add(Conv2D (64, (3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Conv2D (32, (3, 3), activation='relu'))\n",
    "#model.add(Conv20(32, (3, 3), activation=\"relu\"))\n",
    "#flotten the dimension of the image\n",
    "model.add(Flatten())\n",
    "#output Layer with 10 neurons\n",
    "model.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ff4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "# Compile mode\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer =\n",
    "              \"Adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af335870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 153s 78ms/step - loss: 0.2297 - accuracy: 0.9496 - val_loss: 0.0890 - val_accuracy: 0.9713\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 138s 74ms/step - loss: 0.0677 - accuracy: 0.9793 - val_loss: 0.0853 - val_accuracy: 0.9757\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 0.0941 - val_accuracy: 0.9755\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 140s 75ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.1209 - val_accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 138s 74ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.1211 - val_accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d9a6992370>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b1ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics (Test loss & Test Accuracy): \n",
      "[0.12106359004974365, 0.9749000072479248]\n"
     ]
    }
   ],
   "source": [
    "#Observing the metrics\n",
    "# Final evaluation of the model\n",
    "metrics = model.evaluate(x_test, y_test, verbose=8)\n",
    "print(\"Metrics (Test loss & Test Accuracy): \") \n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5da667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "[[7.5828016e-15 2.5196708e-25 2.1200779e-16 7.5312082e-13 6.4813581e-24\n",
      "  7.9925251e-22 3.5580354e-27 1.0000000e+00 8.6040792e-16 4.1065577e-17]\n",
      " [6.2123124e-17 2.7986768e-14 1.0000000e+00 2.7760481e-19 1.0891594e-17\n",
      "  1.3349902e-25 5.1022618e-16 1.5569657e-20 7.5777659e-16 3.9196762e-22]\n",
      " [1.9411820e-12 9.9999404e-01 5.1063512e-06 6.8294258e-13 3.1355082e-08\n",
      "  3.2682621e-09 1.1854252e-10 9.9163522e-08 6.9398669e-07 9.8699549e-15]\n",
      " [9.9999988e-01 3.5072842e-20 1.1498146e-11 9.4269759e-16 2.7598231e-16\n",
      "  7.6828446e-15 6.6758218e-12 5.1336656e-12 1.0471004e-10 8.2694463e-08]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the output\n",
    "prediction= model.predict(x_test[:4])\n",
    "print (prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c74053f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print (np.argmax(prediction, axis=1)) #printing our labels from first 4 images\n",
    "print (y_test[:4]) #printing the actual labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "392a0c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics (Test loss & Test Accuracy): \n",
      "[0.12106359004974365, 0.9749000072479248]\n"
     ]
    }
   ],
   "source": [
    "#Observing the metrics\n",
    "# Final evaluation of the model\n",
    "metrics = model.evaluate(x_test, y_test, verbose=8) \n",
    "print(\"Metrics (Test loss & Test Accuracy): \")\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "861479e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[7.5828016e-15 2.5196708e-25 2.1200779e-16 7.5312082e-13 6.4813581e-24\n",
      "  7.9925251e-22 3.5580354e-27 1.0000000e+00 8.6040792e-16 4.1065577e-17]\n",
      " [6.2123124e-17 2.7986768e-14 1.0000000e+00 2.7760481e-19 1.0891594e-17\n",
      "  1.3349902e-25 5.1022618e-16 1.5569657e-20 7.5777659e-16 3.9196762e-22]\n",
      " [1.9411820e-12 9.9999404e-01 5.1063512e-06 6.8294258e-13 3.1355082e-08\n",
      "  3.2682621e-09 1.1854252e-10 9.9163522e-08 6.9398669e-07 9.8699549e-15]\n",
      " [9.9999988e-01 3.5072842e-20 1.1498146e-11 9.4269759e-16 2.7598231e-16\n",
      "  7.6828446e-15 6.6758218e-12 5.1336656e-12 1.0471004e-10 8.2694463e-08]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the output\n",
    "prediction= model.predict(x_test[:4]) \n",
    "print (prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "056b7bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print (np.argmax(prediction, axis=1)) #printing our labels from first 4 images\n",
    "print (y_test[:4]) #printing the actual labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ba13492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "# Save the model\n",
    "model.save('models/mnistCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ab6be2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "[[9.9999988e-01 3.5072842e-20 1.1498103e-11 9.4270479e-16 2.7598337e-16\n",
      "  7.6827862e-15 6.6757710e-12 5.1336461e-12 1.0471024e-10 8.2694307e-08]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[9.9999988e-01 3.5072842e-20 1.1498103e-11 9.4270479e-16 2.7598337e-16\n",
      "  7.6827862e-15 6.6757710e-12 5.1336461e-12 1.0471024e-10 8.2694307e-08]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[9.9999988e-01 3.5072842e-20 1.1498103e-11 9.4270479e-16 2.7598337e-16\n",
      "  7.6827862e-15 6.6757710e-12 5.1336461e-12 1.0471024e-10 8.2694307e-08]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[9.9999988e-01 3.5072842e-20 1.1498103e-11 9.4270479e-16 2.7598337e-16\n",
      "  7.6827862e-15 6.6757710e-12 5.1336461e-12 1.0471024e-10 8.2694307e-08]]\n"
     ]
    }
   ],
   "source": [
    "#Taking images as input and checking results\n",
    "#Importing the Keras Libraries and packages\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(r'C:\\Users\\karthik\\models\\mnistCNN.h5')\n",
    "from PIL import Image # used for manipulating image uploaded by the user.\n",
    "import numpy as np #used for numerical analysis\n",
    "for index in range(4):\n",
    "    img = Image.open(r\"C:\\Users\\karthik\\PROJECT IBM\\models\\archive\\mnist_png\\mnist_png\\testing\\0\\3.png\") #convert image to monochrome\n",
    "\n",
    "    img = img.resize((28,28))# resizing of input image\n",
    "    im2arr =  np.array(img) #converting to image\n",
    "    im2arr = im2arr.reshape(1,28,28,1) #reshaping according to our requirement\n",
    "    #Predicting the Test set results\n",
    "    y_pred =  model.predict(im2arr) #predicting the results\n",
    "    print(y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
